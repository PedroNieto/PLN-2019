{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tass import InterTASSReader\n",
    "from analysis import print_maxent_features, print_feature_weights_for_item\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    tassDev = InterTASSReader(\"InterTASS/ES/intertass-ES-development-tagged.xml\")\n",
    "    X_dev = list(tassDev.X())\n",
    "    y_dev = list(tassDev.y())\n",
    "\n",
    "    tassTrain = InterTASSReader(\"InterTASS/ES/intertass-ES-train-tagged.xml\")\n",
    "    X_train = list(tassTrain.X())\n",
    "    y_train = list(tassTrain.y())\n",
    "\n",
    "    return X_dev, y_dev, X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev, y_dev, X_train, y_train = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/.virtualenvs/pln/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/pedro/.virtualenvs/pln/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/pedro/.virtualenvs/pln/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/pedro/.virtualenvs/pln/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from classifier import SentimentClassifier\n",
    "\n",
    "sentimentClassifier = SentimentClassifier(clf = 'maxent')\n",
    "sentimentClassifier.fit(X_train, y_train, X_dev, y_dev)\n",
    "pipeline = sentimentClassifier._pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = pipeline.named_steps['vect']\n",
    "clf = pipeline.named_steps['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vect.get_feature_names()\n",
    "coef = clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N:\n",
      "\t! gracias mejor buena primer ([-0.83044966 -0.45699408 -0.44051692 -0.36302183 -0.35821204 -0.35254213\n",
      " -0.33985407 -0.32972154 -0.31863342 -0.29588705])\n",
      "\tNOT_ni odio mal triste no ([0.27003069 0.30371244 0.30411346 0.31481355 0.32240395 0.33303664\n",
      " 0.43855286 0.53304974 0.58158978 0.84728895])\n",
      "NEU:\n",
      "\t! gracias hoy hacer quiero ([-0.44498438 -0.43189308 -0.3006553  -0.25977253 -0.24825548 -0.22946173\n",
      " -0.22896164 -0.21985821 -0.20754978 -0.20266067])\n",
      "\thombre NOT_pasa vez sido aunque ([0.1743627  0.18099543 0.20616629 0.21507509 0.21525027 0.22326693\n",
      " 0.23003609 0.24993635 0.29292053 0.3388004 ])\n",
      "NONE:\n",
      "\tno ... ! mal , ([-0.62669427 -0.42365885 -0.35421905 -0.27651121 -0.26400719 -0.25237283\n",
      " -0.2320382  -0.22947012 -0.22896592 -0.22804821])\n",
      "\tjugar alguna semana \" ? ([0.19184573 0.19904559 0.23808361 0.24237828 0.28254938 0.30848274\n",
      " 0.313934   0.31416905 0.40413254 0.89216705])\n",
      "P:\n",
      "\tno ? triste mal ni ([-0.68846476 -0.56128492 -0.37451977 -0.30823815 -0.24716562 -0.23501746\n",
      " -0.2295504  -0.22594837 -0.21200132 -0.20143871])\n",
      "\tgenial mejor buen gracias ! ([0.34686752 0.37556711 0.37852706 0.39381561 0.40103636 0.49071308\n",
      " 0.53876274 0.61864477 0.75299131 1.07735273])\n"
     ]
    }
   ],
   "source": [
    "print_maxent_features(vect, clf, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis\n",
    "\n",
    "En general tienen sentido, la mayor√≠a de los features son palabras con clara carga semantica. *mal*, *triste*, *no*, se asocian con sentimientos negativos que es lo que uno esperar√≠a. Lo mismo pasa con las palabras asociadas a sentimientos positivos. Sin embargo las palabras asociadas con **NONE** y **NEU** no son tan claras, por lo menos las que tienen peso positivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "y_pred = pipeline.predict(X_dev)\n",
    "\n",
    "y_prob = pipeline.predict_proba(X_dev)\n",
    "\n",
    "probs = {\"N\":0,\"NEU\":1,\"NONE\":2,\"P\":3}\n",
    "\n",
    "errors = []\n",
    "for i, (x, y1, y2, y3) in enumerate(zip(X_dev, y_dev, y_pred, y_prob)):\n",
    "    if y1 != y2:\n",
    "        errors.append({\n",
    "            'index': i,\n",
    "            'item': x,\n",
    "            'true': y1,\n",
    "            'pred': y2,\n",
    "            'pred_prob': y3[probs[y2]],\n",
    "            'true_prob': y3[probs[y1]]})\n",
    "\n",
    "errdf = pd.DataFrame(errors)\n",
    "errdf['len'] = errdf['item'].apply(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>item</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "      <th>true</th>\n",
       "      <th>true_prob</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>146</td>\n",
       "      <td>La persona vale para algo. Otra cosa es que no...</td>\n",
       "      <td>N</td>\n",
       "      <td>0.668041</td>\n",
       "      <td>P</td>\n",
       "      <td>0.147123</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>191</td>\n",
       "      <td>@Nadieelosabe Vale vuelvo a preguntar. No sabi...</td>\n",
       "      <td>N</td>\n",
       "      <td>0.649930</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0.081780</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>217</td>\n",
       "      <td>@LovNaty Tu vida ha parido a un grandisimo hij...</td>\n",
       "      <td>P</td>\n",
       "      <td>0.643372</td>\n",
       "      <td>N</td>\n",
       "      <td>0.197041</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>333</td>\n",
       "      <td>No silencio lo que calla. Es la vida suspendid...</td>\n",
       "      <td>N</td>\n",
       "      <td>0.641812</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0.066547</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>437</td>\n",
       "      <td>Esta decidido. ¬°Habr√° Modo Carrera en el canal...</td>\n",
       "      <td>P</td>\n",
       "      <td>0.637488</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0.140280</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>320</td>\n",
       "      <td>A m√≠ nunca me podr√°n hacer una broma porque no...</td>\n",
       "      <td>N</td>\n",
       "      <td>0.636474</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0.106083</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>100</td>\n",
       "      <td>@gilthoniel_1987 Si estoy trabajando üò≠, con vi...</td>\n",
       "      <td>P</td>\n",
       "      <td>0.634568</td>\n",
       "      <td>NEU</td>\n",
       "      <td>0.091338</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>270</td>\n",
       "      <td>@MV3ga hay cosas del hilo con las que discrepo...</td>\n",
       "      <td>N</td>\n",
       "      <td>0.629306</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0.078026</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>430</td>\n",
       "      <td>@TichKhan_ d los cines donde la hacen este fin...</td>\n",
       "      <td>N</td>\n",
       "      <td>0.627497</td>\n",
       "      <td>P</td>\n",
       "      <td>0.147824</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>417</td>\n",
       "      <td>@CucoRguez Ya, estoy jugando al rat√≥n y al gat...</td>\n",
       "      <td>N</td>\n",
       "      <td>0.624486</td>\n",
       "      <td>P</td>\n",
       "      <td>0.158688</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@piscolabisaereo @HistoriaNG @SPosteguillo las...</td>\n",
       "      <td>N</td>\n",
       "      <td>0.624359</td>\n",
       "      <td>P</td>\n",
       "      <td>0.165209</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>343</td>\n",
       "      <td>Tambien subire el changelog a lo largo de esto...</td>\n",
       "      <td>P</td>\n",
       "      <td>0.616850</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0.133971</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>103</td>\n",
       "      <td>@ElnAlfaro S√≠. En realidad no pensaba q fueran...</td>\n",
       "      <td>N</td>\n",
       "      <td>0.614321</td>\n",
       "      <td>NEU</td>\n",
       "      <td>0.135720</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>277</td>\n",
       "      <td>Mi madre me deja ponerme rubia pero no el pelo...</td>\n",
       "      <td>N</td>\n",
       "      <td>0.614126</td>\n",
       "      <td>NEU</td>\n",
       "      <td>0.123345</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>132</td>\n",
       "      <td>@mividaaburrida @juanpabloraba por dios que gu...</td>\n",
       "      <td>N</td>\n",
       "      <td>0.612870</td>\n",
       "      <td>NEU</td>\n",
       "      <td>0.122775</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>313</td>\n",
       "      <td>\"No tenemos la sensaci√≥n de ir a un trabajo\", ...</td>\n",
       "      <td>N</td>\n",
       "      <td>0.612600</td>\n",
       "      <td>P</td>\n",
       "      <td>0.150614</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>410</td>\n",
       "      <td>No puedo evitar ir a beber una lata de refresc...</td>\n",
       "      <td>N</td>\n",
       "      <td>0.611957</td>\n",
       "      <td>NEU</td>\n",
       "      <td>0.120376</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>336</td>\n",
       "      <td>@ItsMeCar0l ¬°Hooola, buenas! Soy el que ten√≠a ...</td>\n",
       "      <td>P</td>\n",
       "      <td>0.610257</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0.112990</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>223</td>\n",
       "      <td>Cuando no puedo dormir, escribo todo lo que pr...</td>\n",
       "      <td>N</td>\n",
       "      <td>0.608080</td>\n",
       "      <td>P</td>\n",
       "      <td>0.168811</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>175</td>\n",
       "      <td>@Tokpelotas @Carlbozal +1 y coincido, no imagi...</td>\n",
       "      <td>N</td>\n",
       "      <td>0.604804</td>\n",
       "      <td>P</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                               item pred  pred_prob  \\\n",
       "63     146  La persona vale para algo. Otra cosa es que no...    N   0.668041   \n",
       "82     191  @Nadieelosabe Vale vuelvo a preguntar. No sabi...    N   0.649930   \n",
       "93     217  @LovNaty Tu vida ha parido a un grandisimo hij...    P   0.643372   \n",
       "154    333  No silencio lo que calla. Es la vida suspendid...    N   0.641812   \n",
       "190    437  Esta decidido. ¬°Habr√° Modo Carrera en el canal...    P   0.637488   \n",
       "145    320  A m√≠ nunca me podr√°n hacer una broma porque no...    N   0.636474   \n",
       "41     100  @gilthoniel_1987 Si estoy trabajando üò≠, con vi...    P   0.634568   \n",
       "119    270  @MV3ga hay cosas del hilo con las que discrepo...    N   0.629306   \n",
       "189    430  @TichKhan_ d los cines donde la hacen este fin...    N   0.627497   \n",
       "185    417  @CucoRguez Ya, estoy jugando al rat√≥n y al gat...    N   0.624486   \n",
       "1        1  @piscolabisaereo @HistoriaNG @SPosteguillo las...    N   0.624359   \n",
       "158    343  Tambien subire el changelog a lo largo de esto...    P   0.616850   \n",
       "43     103  @ElnAlfaro S√≠. En realidad no pensaba q fueran...    N   0.614321   \n",
       "124    277  Mi madre me deja ponerme rubia pero no el pelo...    N   0.614126   \n",
       "58     132  @mividaaburrida @juanpabloraba por dios que gu...    N   0.612870   \n",
       "142    313  \"No tenemos la sensaci√≥n de ir a un trabajo\", ...    N   0.612600   \n",
       "183    410  No puedo evitar ir a beber una lata de refresc...    N   0.611957   \n",
       "156    336  @ItsMeCar0l ¬°Hooola, buenas! Soy el que ten√≠a ...    P   0.610257   \n",
       "97     223  Cuando no puedo dormir, escribo todo lo que pr...    N   0.608080   \n",
       "74     175  @Tokpelotas @Carlbozal +1 y coincido, no imagi...    N   0.604804   \n",
       "\n",
       "     true  true_prob  len  \n",
       "63      P   0.147123  134  \n",
       "82   NONE   0.081780   67  \n",
       "93      N   0.197041   91  \n",
       "154  NONE   0.066547  126  \n",
       "190  NONE   0.140280  133  \n",
       "145  NONE   0.106083   88  \n",
       "41    NEU   0.091338   73  \n",
       "119  NONE   0.078026  133  \n",
       "189     P   0.147824  138  \n",
       "185     P   0.158688  120  \n",
       "1       P   0.165209   95  \n",
       "158  NONE   0.133971  101  \n",
       "43    NEU   0.135720   87  \n",
       "124   NEU   0.123345   54  \n",
       "58    NEU   0.122775  101  \n",
       "142     P   0.150614  132  \n",
       "183   NEU   0.120376  120  \n",
       "156  NONE   0.112990   93  \n",
       "97      P   0.168811  125  \n",
       "74      P   0.185151  129  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(errdf.sort_values('pred_prob', ascending=False)[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis de un error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_dev[146]\n",
    "tweet = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2/3 de la palabra no son features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'la persona vale para algo. otra cosa es que no te creas lo maravilloso y ese arte que puedes desplegar..fingelo hasta que se exprese.\\n'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet.split()) #24\n",
    "len(set(tweet.split()) - set(features)) #16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Palabras mal takenizadas y desconocidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NOT_arte',\n",
       " 'NOT_desplegar',\n",
       " 'NOT_exprese',\n",
       " 'NOT_fingelo',\n",
       " 'NOT_maravilloso',\n",
       " 'NOT_puedes'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from tokenizer import CustomTokenizer\n",
    "\n",
    "tokenizer = CustomTokenizer()\n",
    "words = set(tokenizer.tokenize(tweet)) - set(features)\n",
    "words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features involucrados y sus pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". [ 0.1357706  -0.1417081  -0.22804821 -0.08348188]\n",
      "NOT_.. [ 0.00345008 -0.02806548  0.08089263 -0.05376528]\n",
      "NOT_creas [-0.07001599 -0.01495925 -0.00889087  0.09251963]\n",
      "cosa [ 0.30371244 -0.14239191 -0.1394941  -0.07827462]\n",
      "no [ 0.84728895 -0.17918136 -0.62669427 -0.68846476]\n",
      "persona [ 0.01349378  0.03250738 -0.15414068  0.05096104]\n",
      "vale [ 0.05107103 -0.0761001   0.10967915 -0.11173736]\n"
     ]
    }
   ],
   "source": [
    "print_feature_weights_for_item(vect,clf,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La presencia del token *no*, incrementa el demaciado el peso de **N**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66804128, 0.10540516, 0.07943104, 0.14712252],\n",
       "       [0.42891679, 0.11282748, 0.12079086, 0.33746486]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x = x.replace('no','')\n",
    "pipeline.predict_proba([x, new_x])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es de esperar si removemos ese token la probabilidad de **N** disminuye. Sinembargo no lo suficiente como para que se determine correctamente la clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66804128, 0.10540516, 0.07943104, 0.14712252],\n",
       "       [0.66804128, 0.10540516, 0.07943104, 0.14712252]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x = x.replace('desplegar..fingelo','desplegar .. fingelo')\n",
    "pipeline.predict_proba([x, new_x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que corregir la tokenizacion no tiene ningun efecto. Quizas con data augmentation se podr√≠a obtener un mejor resultado, ya que hay varias palabras desconocidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
